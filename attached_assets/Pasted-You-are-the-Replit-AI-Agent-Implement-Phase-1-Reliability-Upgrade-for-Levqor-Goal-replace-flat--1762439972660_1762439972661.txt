You are the Replit AI Agent. Implement Phase 1: Reliability Upgrade for Levqor. Goal = replace flat JSON storage with Postgres, add metrics (Prometheus-style), daily backup, and alerting. Work safely and atomically.

STEPS
1. ENV
   - Add secrets if missing:
     DATABASE_URL=postgresql+psycopg2://user:pass@localhost:5432/levqor
     PG_USER,PG_PASS,PG_DB=levqor
   - pip install psycopg2-binary prometheus_client schedule

2. DB SETUP
   - Create file `db_init.py`:
     ```python
     import psycopg2,os
     conn=psycopg2.connect(os.getenv("DATABASE_URL"))
     cur=conn.cursor()
     cur.execute("""CREATE TABLE IF NOT EXISTS ledger(
       id SERIAL PRIMARY KEY,
       event JSONB,
       created_at TIMESTAMP DEFAULT NOW());""")
     cur.execute("""CREATE TABLE IF NOT EXISTS health(
       id SERIAL PRIMARY KEY,
       metric TEXT,value NUMERIC,created_at TIMESTAMP DEFAULT NOW());""")
     conn.commit(); conn.close()
     ```
   - Run once: `python3 db_init.py`.

3. MIGRATE LEDGER
   - Create `scripts/migrate_ledger.py`:
     ```python
     import json,psycopg2,os
     conn=psycopg2.connect(os.getenv("DATABASE_URL"))
     cur=conn.cursor()
     for line in open("data/ledger.jsonl"):
         cur.execute("INSERT INTO ledger(event) VALUES(%s)",(json.loads(line),))
     conn.commit(); conn.close()
     print("✅ Ledger migrated")
     ```

4. BACKEND INTEGRATION
   - In `run.py`, replace file-write logic with:
     ```python
     def log_event(evt):
         import psycopg2,os,json
         conn=psycopg2.connect(os.getenv("DATABASE_URL"))
         cur=conn.cursor(); cur.execute("INSERT INTO ledger(event) VALUES(%s)",(json.dumps(evt),))
         conn.commit(); conn.close()
     ```
   - Add `/metrics` endpoint:
     ```python
     from prometheus_client import CollectorRegistry,Counter,generate_latest
     registry=CollectorRegistry()
     hits=Counter("api_requests","API hits",registry=registry)
     @app.before_request
     def _count(): hits.inc()
     @app.route("/metrics")
     def metrics(): return generate_latest(registry),200,{"Content-Type":"text/plain"}
     ```

5. DAILY BACKUP
   - Create `scripts/db_backup.py`:
     ```python
     import os,datetime,subprocess
     ts=datetime.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
     subprocess.run(["pg_dump","--no-owner","-d",os.getenv("DATABASE_URL"),
                     "-f",f"backups/db_{ts}.sql"],check=False)
     ```
   - Add scheduler entry (in `scheduler.py`):
     ```python
     from schedule import every,run_pending; import time,subprocess
     every().day.at("00:30").do(lambda: subprocess.run(["python3","scripts/db_backup.py"]))
     while True: run_pending(); time.sleep(60)
     ```

6. ALERT HOOK
   - In `autoselftest.py`, after each test:
     ```python
     if fail: notifier.alert("DB/Metric Failure",msg)
     ```

7. VERIFY
   - Run:
     ```
     python3 db_init.py
     python3 scripts/migrate_ledger.py
     curl -s localhost:5000/metrics | head
     ```
   - Expect “api_requests_total” metric and “✅ Ledger migrated”.

8. OUTPUT SUMMARY
   - Print:
     ```
     Database: OK
     Metrics: OK (/metrics)
     Backup: OK (backups/db_*.sql)
     Alerts: OK
     Ledger entries: COUNT(*)
     ```

SAFETY
- Never drop existing files unless migration passes.
- Back up ledger.jsonl before writing.
- Exit on any psycopg2 error.
- Keep rollback.sh untouched.